{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vsRGyGSfVYMB"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from datasets import CustomCOCOADataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = 'val'\n",
    "root_dict = {'train': \"../data/COCOA/train2014\", 'val': \"../data/COCOA/val2014\"}\n",
    "\n",
    "img_root = root_dict[phase]\n",
    "annot_path = \"../data/COCOA/annotations/COCO_amodal_{}2014.json\".format(phase)\n",
    "\n",
    "data_reader = CustomCOCOADataset(annot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "val_dataloader = DataLoader(data_reader, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "wzmE6yXkuQ3X"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=9, init_features=32):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(\n",
    "            features * 16, features * 8, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
    "        self.upconv3 = nn.ConvTranspose2d(\n",
    "            features * 8, features * 4, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
    "        self.upconv2 = nn.ConvTranspose2d(\n",
    "            features * 4, features * 2, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
    "        self.upconv1 = nn.ConvTranspose2d(\n",
    "            features * 2, features, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        \n",
    "        dec0 = self.conv(dec1)\n",
    "        return torch.sigmoid(dec0[0]), torch.tanh(dec0[1:])\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(epochs, device, net, losses, optimizer, train_loader, val_loader,\n",
    "          in_key=0, target_key=1, mask_key=2, loss_alpha=0.5, scheduler=None, \n",
    "          checkpoint=False, checkpoint_dir='./models/', exp_name='unet'):\n",
    "    net = net.to(device)\n",
    "    loss_seg, loss_graph = losses\n",
    "    \n",
    "    # Create checkpoint dir\n",
    "    logging_dir_name = exp_name + '_' + str(time.time()) + '/'\n",
    "    checkpoint_dir = checkpoint_dir + logging_dir_name\n",
    "    os.mkdir(checkpoint_dir)\n",
    "    \n",
    "    # Phases and Logging\n",
    "    phases = { 'train': train_loader, \n",
    "               'val': val_loader }\n",
    "    start_time = time.time()\n",
    "    train_log = []\n",
    "\n",
    "    # Training\n",
    "    for i in range(epochs):\n",
    "        epoch_data = { 'train_mean_loss_seg': 0.0, 'train_mean_loss_graph': 0.0,\n",
    "                       'val_mean_loss_seg': 0.0, 'val_mean_loss_graph': 0.0 }\n",
    "        for phase, loader in phases.items():\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "            \n",
    "            running_losses = np.zeros(2)\n",
    "            for batch in tqdm(loader):\n",
    "                _in, _out, _mask = batch[in_key].to(device), batch[target_key].to(device), batch[mask_key].to(device)\n",
    "                _out_seg, _out_graph = _out\n",
    "                \n",
    "                # Forward\n",
    "                optimizer.zero_grad()\n",
    "                output_seg, output_graph = net(_in)\n",
    "                \n",
    "                # Apply graph loss to masked outputs\n",
    "                output_graph, _out_graph = output_graph[_mask != 0], _out_graph[_mask != 0]\n",
    "                loss0, loss1 = loss_seg(output_seg, _out_seg), loss_graph(output_graph, _out_graph)\n",
    "                loss = alpha * loss0 + (1 - alpha) * loss1\n",
    "                \n",
    "                # Optimize\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    \n",
    "                # Log batch results\n",
    "                running_losses += [loss0.item(), loss1.item()]\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "            # Log phase results\n",
    "            running_loss_seg, running_loss_graph = running_losses\n",
    "            epoch_data[phase + '_mean_loss_seg'] = running_loss_seg / len(loader)\n",
    "            epoch_data[phase + '_mean_loss_graph'] = running_loss_graph / len(loader)\n",
    "\n",
    "        # Display Progress\n",
    "        duration_elapsed = time.time() - start_time\n",
    "        print('\\n-- Finished Epoch {}/{} --'.format(i, epochs - 1))\n",
    "        print('Training Loss (Segmentation): {}'.format(epoch_data['train_mean_loss_seg']))\n",
    "        print('Training Loss (Graph): {}'.format(epoch_data['train_mean_loss_graph']))\n",
    "        print('Validation Loss (Segmentation): {}'.format(epoch_data['val_mean_loss_seg']))\n",
    "        print('Validation Loss (Graph): {}'.format(epoch_data['val_mean_loss_graph']))\n",
    "        print('Time since start: {}'.format(duration_elapsed))\n",
    "        epoch_data['time_elapsed'] = duration_elapsed\n",
    "        train_log.append(epoch_data)\n",
    "\n",
    "        # Scheduler\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        # Checkpoint\n",
    "        if checkpoint:\n",
    "            path = checkpoint_dir + 'checkpoint_' + str(i) + '_' + str(time.time())\n",
    "            torch.save(net.state_dict(), path)\n",
    "\n",
    "        # Save train_log\n",
    "        path = checkpoint_dir + 'train_log_' + str(time.time()) \n",
    "        with open(path, 'wb') as fp:\n",
    "            pickle.dump(train_log, fp)\n",
    "\n",
    "    return train_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 392,
     "status": "ok",
     "timestamp": 1618023896816,
     "user": {
      "displayName": "Briana Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjdwetoa6LIfFqOnjqFLSYVcVF68sC1Q7rHXKnLFA=s64",
      "userId": "10858716679377069069"
     },
     "user_tz": 300
    },
    "id": "gu1pzRrqvR65",
    "outputId": "ad34545b-8195-492b-da68-f4e564c484bf"
   },
   "outputs": [],
   "source": [
    "net = UNet()\n",
    "cuda_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = net.to(cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ckMxy3FdVqZP"
   },
   "outputs": [],
   "source": [
    "crit1 = nn.CrossEntropyLoss()\n",
    "crit2 = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-05)\n",
    "\n",
    "# TODO: add scheduler\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[epochs to drop], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expects loaders to return (input image, (target segmentation, target graph), mask)\n",
    "\n",
    "# train_loader = ...\n",
    "# val_loader = ...\n",
    "train(10, cuda_device, net, [crit1, crit2], optimizer, train_loader, val_loader, \n",
    "      loss_alpha=0.5, scheduler=None, checkpoint=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNupobF3Cu0yqdBpqggUlNJ",
   "collapsed_sections": [],
   "name": "U-Net scratch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
